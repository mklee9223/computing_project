{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install xgboost\n!pip install polars\n!pip install optuna\n!pip install missingno\n!pip install lightgbm\n!pip install catboost\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-02T03:28:07.362411Z","iopub.execute_input":"2024-12-02T03:28:07.362858Z","iopub.status.idle":"2024-12-02T03:29:04.530018Z","shell.execute_reply.started":"2024-12-02T03:28:07.362819Z","shell.execute_reply":"2024-12-02T03:29:04.528208Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.14.1)\nRequirement already satisfied: polars in /opt/conda/lib/python3.10/site-packages (1.9.0)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (4.0.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.3)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.30)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\nRequirement already satisfied: missingno in /opt/conda/lib/python3.10/site-packages (0.5.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from missingno) (1.26.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from missingno) (3.7.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from missingno) (1.14.1)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from missingno) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->missingno) (2.9.0.post0)\nRequirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn->missingno) (2.2.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->missingno) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn->missingno) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (4.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.14.1)\nRequirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.7)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.26.4)\nRequirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.2.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.14.1)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.22.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.3.0)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport pandas as pd\nfrom sklearn.base import clone\nfrom copy import deepcopy\nimport optuna\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport re\nfrom colorama import Fore, Style\n\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = None\n\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\nimport xgboost as xgb\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\nSEED = 5400\nn_splits = 5\n\ntrain = pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/train.csv\")\ntest =pd.read_csv(\"/kaggle/input/child-mind-institute-problematic-internet-use/test.csv\")\n\n\ntrain = train.dropna(subset=['sii'])\n\n\ntrain['PAQ_PAQ_Total'] = train['PAQ_C-PAQ_C_Total'].add(train['PAQ_A-PAQ_A_Total'],fill_value=0)\n# train['PAQ_PAQ_Total'].isnull().sum()/len(train['PAQ_PAQ_Total'])\n# train\ntrain['Fitness_Endurance_Time']= train['Fitness_Endurance-Time_Mins']*60+train['Fitness_Endurance-Time_Sec']\ntrain=train.drop('PAQ_C-PAQ_C_Total', axis=1)\ntrain=train.drop('PAQ_A-PAQ_A_Total', axis=1)\ntrain=train.drop('Fitness_Endurance-Time_Mins', axis=1)\ntrain=train.drop('Fitness_Endurance-Time_Sec', axis=1)\n\ntest['PAQ_PAQ_Total'] = test['PAQ_C-PAQ_C_Total'].add(test['PAQ_A-PAQ_A_Total'],fill_value=0)\ntest['Fitness_Endurance_Time']= test['Fitness_Endurance-Time_Mins']*60+test['Fitness_Endurance-Time_Sec']\ntest=test.drop('PAQ_C-PAQ_C_Total', axis=1)\ntest=test.drop('PAQ_A-PAQ_A_Total', axis=1)\ntest=test.drop('Fitness_Endurance-Time_Mins', axis=1)\ntest=test.drop('Fitness_Endurance-Time_Sec', axis=1)\n\ntest_id = test['id']\n\ntrain = train.drop('id',axis=1)\ntest = test.drop('id',axis=1)\n\nfeaturesCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n       'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n       'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n       'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n       'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n       'Fitness_Endurance_Time',\n       'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n       'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n       'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n       'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n       'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n       'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n       'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n       'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_PAQ_Total', 'PAQ_C-Season',\n       'SDS-Season', 'SDS-SDS_Total_Raw',\n       'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n       'PreInt_EduHx-computerinternet_hoursday','sii']\n\ntrain = train[featuresCols]\n\n\ncat_c = ['Basic_Demos-Enroll_Season','CGAS-Season','Physical-Season','Fitness_Endurance-Season','FGC-Season',\n 'BIA-Season','PAQ_A-Season','PAQ_C-Season','SDS-Season','PreInt_EduHx-Season']\n\n\n\ndef update(df):\n    global cat_c\n    for c in cat_c : \n        df[c] = df[c].fillna('Missing')\n        df[c] = df[c].astype('category')\n        \n    return df\n\ndef create_mapping(column, dataset):\n    unique_values = dataset[column].unique()\n    return {value: idx for idx, value in enumerate(unique_values)}\n\n    \nfor col in cat_c:\n    all_values = pd.concat([train[col], test[col]]).unique()\n    mapping = {value: idx for idx, value in enumerate(all_values)}\n\n    train[col] = train[col].replace(mapping).astype(int)\n    test[col] = test[col].replace(mapping).astype(int)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T03:29:04.533427Z","iopub.execute_input":"2024-12-02T03:29:04.533989Z","iopub.status.idle":"2024-12-02T03:29:04.648222Z","shell.execute_reply.started":"2024-12-02T03:29:04.533936Z","shell.execute_reply":"2024-12-02T03:29:04.647203Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\ndef fill_missing_with_models(train, test, target_column, n_estimators=1000, random_state=5400):\n    train = train.copy()\n    test = test.copy()\n\n    # Determine the model type\n    if train[target_column].dtype == 'object' or target_column in train.select_dtypes(include=['object', 'category']).columns:\n        model_type = 'classification'\n    else:\n        model_type = 'regression'\n\n    # Add a flag to differentiate train and test\n    train['is_train'] = 1\n    test['is_train'] = 0\n\n    # Combine train and test\n    df = pd.concat([train, test], ignore_index=True)\n\n    # Identify features excluding the target column and 'is_train'\n    features_columns = [col for col in df.columns if col not in [target_column, 'is_train']]\n\n    # Drop non-numeric columns from features for regression tasks\n    if model_type == 'regression':\n        numeric_features = df[features_columns].select_dtypes(include=['number']).columns.tolist()\n        features_columns = numeric_features\n\n    # Split into rows with and without missing values\n    df_missing = df[df[target_column].isnull()]\n    df_not_missing = df[~df[target_column].isnull()]\n\n    if df_missing.empty or df_not_missing.empty:\n        print(f\"No missing data in '{target_column}' column or all data are missing.\")\n        return train.drop(columns=['is_train']), test.drop(columns=['is_train'])\n\n    # Prepare training data\n    X_train = df_not_missing[features_columns]\n    y_train = df_not_missing[target_column]\n\n    # Prepare model\n    if model_type == 'regression':\n        model = LGBMRegressor(n_estimators=n_estimators, random_state=random_state)\n    else:\n        model = XGBClassifier(n_estimators=n_estimators, random_state=random_state, verbose=0)  # Suppress verbose output\n\n    # Fit the model\n    model.fit(X_train, y_train)\n\n    # Predict missing values\n    X_pred = df_missing[features_columns]\n    y_pred = model.predict(X_pred)\n\n    # Fill missing values\n    df.loc[df[target_column].isnull(), target_column] = y_pred\n\n    # Split back into train and test\n    train_filled = df[df['is_train'] == 1].drop(columns=['is_train'])\n    test_filled = df[df['is_train'] == 0].drop(columns=['is_train'])\n\n    return train_filled, test_filled\n\n\n# List of columns to fill\n\n# Becasue Fitness_Endurance_Time didn't get fixed well due to high range\n#log\ntrain['Fitness_Endurance_Time']=np.log(train['Fitness_Endurance_Time'])\ntest['Fitness_Endurance_Time']=np.log(test['Fitness_Endurance_Time'])\n\n'''\n# z standardize\ntrain['Fitness_Endurance_Time'] = (train['Fitness_Endurance_Time'] - train['Fitness_Endurance_Time'].mean()) / train['Fitness_Endurance_Time'].std()\ntest['Fitness_Endurance_Time'] = (test['Fitness_Endurance_Time'] - test['Fitness_Endurance_Time'].mean()) / test['Fitness_Endurance_Time'].std()\n'''\n\n\nbasic_cols = [\n    'Basic_Demos-Age', \n    'CGAS-CGAS_Score', 'Physical-BMI', 'Physical-Height', 'Physical-Weight',\n    'Physical-Waist_Circumference',\n    'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n    'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday',\n    'PAQ_PAQ_Total','Basic_Demos-Sex','Fitness_Endurance-Max_Stage','Fitness_Endurance_Time',\n]\n\n# Define categorical columns if necessary\ncat_c1 = ['Basic_Demos-Sex','Fitness_Endurance-Max_Stage']  # Replace with a list of categorical columns, if applicable\ntrain[cat_c1]=train[cat_c1].astype('category')\ntest[cat_c1]=test[cat_c1].astype('category')\n\n# Loop through columns to fill missing values\nfor col in basic_cols:\n    print(f\"开始填补特征: {col}\")\n    train, test = fill_missing_with_models(train, test, col)\n\ntrain['Physical-HeartRate'] = train['Physical-HeartRate'].astype(int)\ntest['Physical-HeartRate'] = test['Physical-HeartRate'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:21:30.835042Z","iopub.execute_input":"2024-12-02T04:21:30.835498Z","iopub.status.idle":"2024-12-02T04:21:35.658035Z","shell.execute_reply.started":"2024-12-02T04:21:30.835461Z","shell.execute_reply":"2024-12-02T04:21:35.656967Z"}},"outputs":[{"name":"stdout","text":"开始填补特征: Basic_Demos-Age\nNo missing data in 'Basic_Demos-Age' column or all data are missing.\n开始填补特征: CGAS-CGAS_Score\nNo missing data in 'CGAS-CGAS_Score' column or all data are missing.\n开始填补特征: Physical-BMI\nNo missing data in 'Physical-BMI' column or all data are missing.\n开始填补特征: Physical-Height\nNo missing data in 'Physical-Height' column or all data are missing.\n开始填补特征: Physical-Weight\nNo missing data in 'Physical-Weight' column or all data are missing.\n开始填补特征: Physical-Waist_Circumference\nNo missing data in 'Physical-Waist_Circumference' column or all data are missing.\n开始填补特征: Physical-Diastolic_BP\nNo missing data in 'Physical-Diastolic_BP' column or all data are missing.\n开始填补特征: Physical-HeartRate\nNo missing data in 'Physical-HeartRate' column or all data are missing.\n开始填补特征: Physical-Systolic_BP\nNo missing data in 'Physical-Systolic_BP' column or all data are missing.\n开始填补特征: SDS-SDS_Total_Raw\nNo missing data in 'SDS-SDS_Total_Raw' column or all data are missing.\n开始填补特征: SDS-SDS_Total_T\nNo missing data in 'SDS-SDS_Total_T' column or all data are missing.\n开始填补特征: PreInt_EduHx-computerinternet_hoursday\nNo missing data in 'PreInt_EduHx-computerinternet_hoursday' column or all data are missing.\n开始填补特征: PAQ_PAQ_Total\nNo missing data in 'PAQ_PAQ_Total' column or all data are missing.\n开始填补特征: Basic_Demos-Sex\nNo missing data in 'Basic_Demos-Sex' column or all data are missing.\n开始填补特征: Fitness_Endurance-Max_Stage\nNo missing data in 'Fitness_Endurance-Max_Stage' column or all data are missing.\n开始填补特征: Fitness_Endurance_Time\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 12930\n[LightGBM] [Info] Number of data points in the train set: 2755, number of used features: 76\n[LightGBM] [Info] Start training from score -0.499876\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"train['BIA-Season'] = train['BIA-Season'].fillna('Other')\ntest['BIA-Season'] = test['BIA-Season'].fillna('Other')\n\n# if only use BIA variables, still have missing, using Phsical- variables help\nBIA = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n    'CGAS-CGAS_Score', 'Physical-BMI', 'Physical-Height', 'Physical-Weight',\n    'Physical-Waist_Circumference','Fitness_Endurance-Max_Stage',\n    'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n    'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday',\n    'PAQ_PAQ_Total','Fitness_Endurance_Time',\n       'BIA-Season',\n       \"BIA-BIA_TBW\",\"BIA-BIA_DEE\",\"BIA-BIA_BMC\",\"BIA-BIA_Fat\", \"BIA-BIA_BMI\",'BIA-BIA_Frame_num',\n       'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM','BIA-BIA_Activity_Level_num',\n      'BIA-BIA_BMR', 'BIA-BIA_ECW', 'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI']\n\n\n\nfor col in BIA:\n    print(\"开始填补特征：\"+ col)\n    train, test = fill_missing_with_models(train, test, col)\n\n\ntrain['BIA-BIA_Frame_num'] = train['BIA-BIA_Frame_num'].astype(int)\ntest['BIA-BIA_Frame_num'] = test['BIA-BIA_Frame_num'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:21:44.475356Z","iopub.execute_input":"2024-12-02T04:21:44.476127Z","iopub.status.idle":"2024-12-02T04:21:44.842977Z","shell.execute_reply.started":"2024-12-02T04:21:44.476086Z","shell.execute_reply":"2024-12-02T04:21:44.841758Z"}},"outputs":[{"name":"stdout","text":"开始填补特征：Basic_Demos-Age\nNo missing data in 'Basic_Demos-Age' column or all data are missing.\n开始填补特征：Basic_Demos-Sex\nNo missing data in 'Basic_Demos-Sex' column or all data are missing.\n开始填补特征：CGAS-CGAS_Score\nNo missing data in 'CGAS-CGAS_Score' column or all data are missing.\n开始填补特征：Physical-BMI\nNo missing data in 'Physical-BMI' column or all data are missing.\n开始填补特征：Physical-Height\nNo missing data in 'Physical-Height' column or all data are missing.\n开始填补特征：Physical-Weight\nNo missing data in 'Physical-Weight' column or all data are missing.\n开始填补特征：Physical-Waist_Circumference\nNo missing data in 'Physical-Waist_Circumference' column or all data are missing.\n开始填补特征：Fitness_Endurance-Max_Stage\nNo missing data in 'Fitness_Endurance-Max_Stage' column or all data are missing.\n开始填补特征：Physical-Diastolic_BP\nNo missing data in 'Physical-Diastolic_BP' column or all data are missing.\n开始填补特征：Physical-HeartRate\nNo missing data in 'Physical-HeartRate' column or all data are missing.\n开始填补特征：Physical-Systolic_BP\nNo missing data in 'Physical-Systolic_BP' column or all data are missing.\n开始填补特征：SDS-SDS_Total_Raw\nNo missing data in 'SDS-SDS_Total_Raw' column or all data are missing.\n开始填补特征：SDS-SDS_Total_T\nNo missing data in 'SDS-SDS_Total_T' column or all data are missing.\n开始填补特征：PreInt_EduHx-computerinternet_hoursday\nNo missing data in 'PreInt_EduHx-computerinternet_hoursday' column or all data are missing.\n开始填补特征：PAQ_PAQ_Total\nNo missing data in 'PAQ_PAQ_Total' column or all data are missing.\n开始填补特征：Fitness_Endurance_Time\nNo missing data in 'Fitness_Endurance_Time' column or all data are missing.\n开始填补特征：BIA-Season\nNo missing data in 'BIA-Season' column or all data are missing.\n开始填补特征：BIA-BIA_TBW\nNo missing data in 'BIA-BIA_TBW' column or all data are missing.\n开始填补特征：BIA-BIA_DEE\nNo missing data in 'BIA-BIA_DEE' column or all data are missing.\n开始填补特征：BIA-BIA_BMC\nNo missing data in 'BIA-BIA_BMC' column or all data are missing.\n开始填补特征：BIA-BIA_Fat\nNo missing data in 'BIA-BIA_Fat' column or all data are missing.\n开始填补特征：BIA-BIA_BMI\nNo missing data in 'BIA-BIA_BMI' column or all data are missing.\n开始填补特征：BIA-BIA_Frame_num\nNo missing data in 'BIA-BIA_Frame_num' column or all data are missing.\n开始填补特征：BIA-BIA_ICW\nNo missing data in 'BIA-BIA_ICW' column or all data are missing.\n开始填补特征：BIA-BIA_LDM\nNo missing data in 'BIA-BIA_LDM' column or all data are missing.\n开始填补特征：BIA-BIA_LST\nNo missing data in 'BIA-BIA_LST' column or all data are missing.\n开始填补特征：BIA-BIA_SMM\nNo missing data in 'BIA-BIA_SMM' column or all data are missing.\n开始填补特征：BIA-BIA_Activity_Level_num\nNo missing data in 'BIA-BIA_Activity_Level_num' column or all data are missing.\n开始填补特征：BIA-BIA_BMR\nNo missing data in 'BIA-BIA_BMR' column or all data are missing.\n开始填补特征：BIA-BIA_ECW\nNo missing data in 'BIA-BIA_ECW' column or all data are missing.\n开始填补特征：BIA-BIA_FFM\nNo missing data in 'BIA-BIA_FFM' column or all data are missing.\n开始填补特征：BIA-BIA_FFMI\nNo missing data in 'BIA-BIA_FFMI' column or all data are missing.\n开始填补特征：BIA-BIA_FMI\nNo missing data in 'BIA-BIA_FMI' column or all data are missing.\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\ndef fill_missing_with_models(train, test, target_column, n_estimators=1000, random_state=5400):\n    train = train.copy()\n    test = test.copy()\n\n    # Determine the model type\n    if train[target_column].dtype == 'object' or target_column in train.select_dtypes(include=['object', 'category']).columns:\n        model_type = 'classification'\n    else:\n        model_type = 'regression'\n\n    # Add a flag to differentiate train and test\n    train['is_train'] = 1\n    test['is_train'] = 0\n\n    # Combine train and test\n    df = pd.concat([train, test], ignore_index=True)\n\n    # Identify features excluding the target column and 'is_train'\n    features_columns = [col for col in df.columns if col not in [target_column, 'is_train']]\n\n    # Drop non-numeric columns from features for regression tasks\n    if model_type == 'regression':\n        numeric_features = df[features_columns].select_dtypes(include=['number']).columns.tolist()\n        features_columns = numeric_features\n\n    # Split into rows with and without missing values\n    df_missing = df[df[target_column].isnull()]\n    df_not_missing = df[~df[target_column].isnull()]\n\n    if df_missing.empty or df_not_missing.empty:\n        print(f\"No missing data in '{target_column}' column or all data are missing.\")\n        return train.drop(columns=['is_train']), test.drop(columns=['is_train'])\n\n    # Prepare training data\n    X_train = df_not_missing[features_columns]\n    y_train = df_not_missing[target_column]\n\n    # Prepare model\n    if model_type == 'regression':\n        model = XGBRegressor(n_estimators=n_estimators, random_state=random_state)\n    else:\n        model = XGBClassifier(n_estimators=n_estimators, random_state=random_state, verbose=0)  # Suppress verbose output\n\n    # Fit the model\n    model.fit(X_train, y_train)\n\n    # Predict missing values\n    X_pred = df_missing[features_columns]\n    y_pred = model.predict(X_pred)\n\n    # Fill missing values\n    df.loc[df[target_column].isnull(), target_column] = y_pred\n\n    # Split back into train and test\n    train_filled = df[df['is_train'] == 1].drop(columns=['is_train'])\n    test_filled = df[df['is_train'] == 0].drop(columns=['is_train'])\n\n    return train_filled, test_filled\n\n\nFGC_cols = ['Basic_Demos-Age', \n    'Physical-BMI', 'Physical-Height', 'Physical-Weight',\n    'Physical-Waist_Circumference',\n    'Physical-Diastolic_BP', 'Physical-Systolic_BP',\n    'Fitness_Endurance-Max_Stage','Fitness_Endurance_Time',\n  'FGC-FGC_CU',\n  'FGC-FGC_CU_Zone',\n  'FGC-FGC_GSND',\n  'FGC-FGC_GSND_Zone',\n  'FGC-FGC_GSD',\n  'FGC-FGC_GSD_Zone',\n  'FGC-FGC_PU',\n  'FGC-FGC_PU_Zone',\n  'FGC-FGC_SRL',\n  'FGC-FGC_SRL_Zone',\n  'FGC-FGC_SRR',\n  'FGC-FGC_SRR_Zone',\n  'FGC-FGC_TL',\n  'FGC-FGC_TL_Zone'\n]\n\n\n\nfor col in FGC_cols:\n    print(\"开始填补特征：\"+ col)\n    train, test = fill_missing_with_models(train, test, col)\n\ntrain['FGC-FGC_CU_Zone']=train['FGC-FGC_CU_Zone'].astype(int)\ntrain['FGC-FGC_GSND_Zone']=train['FGC-FGC_GSND_Zone'].astype(int)\ntrain['FGC-FGC_GSD_Zone']=train['FGC-FGC_GSD_Zone'].astype(int)\ntrain['FGC-FGC_SRL_Zone']=train['FGC-FGC_SRL_Zone'].astype(int)\ntrain['FGC-FGC_SRR_Zone']=train['FGC-FGC_SRR_Zone'].astype(int)\ntrain['FGC-FGC_TL_Zone']=train['FGC-FGC_TL_Zone'].astype(int)\n\n\ntest['FGC-FGC_CU_Zone']=test['FGC-FGC_CU_Zone'].astype(int)\ntest['FGC-FGC_GSND_Zone']=test['FGC-FGC_GSND_Zone'].astype(int)\ntest['FGC-FGC_GSD_Zone']=test['FGC-FGC_GSD_Zone'].astype(int)\ntest['FGC-FGC_SRL_Zone']=test['FGC-FGC_SRL_Zone'].astype(int)\ntest['FGC-FGC_SRR_Zone']=test['FGC-FGC_SRR_Zone'].astype(int)\ntest['FGC-FGC_TL_Zone']=test['FGC-FGC_TL_Zone'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:21:50.920291Z","iopub.execute_input":"2024-12-02T04:21:50.921124Z","iopub.status.idle":"2024-12-02T04:21:51.163625Z","shell.execute_reply.started":"2024-12-02T04:21:50.921083Z","shell.execute_reply":"2024-12-02T04:21:51.162666Z"}},"outputs":[{"name":"stdout","text":"开始填补特征：Basic_Demos-Age\nNo missing data in 'Basic_Demos-Age' column or all data are missing.\n开始填补特征：Physical-BMI\nNo missing data in 'Physical-BMI' column or all data are missing.\n开始填补特征：Physical-Height\nNo missing data in 'Physical-Height' column or all data are missing.\n开始填补特征：Physical-Weight\nNo missing data in 'Physical-Weight' column or all data are missing.\n开始填补特征：Physical-Waist_Circumference\nNo missing data in 'Physical-Waist_Circumference' column or all data are missing.\n开始填补特征：Physical-Diastolic_BP\nNo missing data in 'Physical-Diastolic_BP' column or all data are missing.\n开始填补特征：Physical-Systolic_BP\nNo missing data in 'Physical-Systolic_BP' column or all data are missing.\n开始填补特征：Fitness_Endurance-Max_Stage\nNo missing data in 'Fitness_Endurance-Max_Stage' column or all data are missing.\n开始填补特征：Fitness_Endurance_Time\nNo missing data in 'Fitness_Endurance_Time' column or all data are missing.\n开始填补特征：FGC-FGC_CU\nNo missing data in 'FGC-FGC_CU' column or all data are missing.\n开始填补特征：FGC-FGC_CU_Zone\nNo missing data in 'FGC-FGC_CU_Zone' column or all data are missing.\n开始填补特征：FGC-FGC_GSND\nNo missing data in 'FGC-FGC_GSND' column or all data are missing.\n开始填补特征：FGC-FGC_GSND_Zone\nNo missing data in 'FGC-FGC_GSND_Zone' column or all data are missing.\n开始填补特征：FGC-FGC_GSD\nNo missing data in 'FGC-FGC_GSD' column or all data are missing.\n开始填补特征：FGC-FGC_GSD_Zone\nNo missing data in 'FGC-FGC_GSD_Zone' column or all data are missing.\n开始填补特征：FGC-FGC_PU\nNo missing data in 'FGC-FGC_PU' column or all data are missing.\n开始填补特征：FGC-FGC_PU_Zone\nNo missing data in 'FGC-FGC_PU_Zone' column or all data are missing.\n开始填补特征：FGC-FGC_SRL\nNo missing data in 'FGC-FGC_SRL' column or all data are missing.\n开始填补特征：FGC-FGC_SRL_Zone\nNo missing data in 'FGC-FGC_SRL_Zone' column or all data are missing.\n开始填补特征：FGC-FGC_SRR\nNo missing data in 'FGC-FGC_SRR' column or all data are missing.\n开始填补特征：FGC-FGC_SRR_Zone\nNo missing data in 'FGC-FGC_SRR_Zone' column or all data are missing.\n开始填补特征：FGC-FGC_TL\nNo missing data in 'FGC-FGC_TL' column or all data are missing.\n开始填补特征：FGC-FGC_TL_Zone\nNo missing data in 'FGC-FGC_TL_Zone' column or all data are missing.\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"train = update(train)\ntest = update(test)\n\n# interaction feature\ndef create_interaction_features(df, feature_pairs):\n    global cat_c\n    for feature1, feature2 in feature_pairs:\n        if feature1 not in cat_c or feature2 not in cat_c:\n            print(\"feature1: \" + feature1 + \", feature2: \" + feature2)\n            new_feature_name = f\"{feature1}x{feature2}\"\n            df[new_feature_name] = df[feature1] * df[feature2]\n    return df\n\ndef create_division_features(df, feature_pairs):\n    global cat_c\n    for feature1, feature2 in feature_pairs:\n        if feature1 not in cat_c or feature2 not in cat_c:\n            print(f\"feature1: {feature1}, feature2: {feature2}\")\n            \n            # Create A/B feature, handle division by zero or NaN\n            new_feature_name1 = f\"{feature1}div{feature2}\"\n            df[new_feature_name1] = df[feature1] / df[feature2]\n            \n            # Mask NaN or zero values\n            df[new_feature_name1] = df[new_feature_name1].mask((df[feature1] == 0) | (df[feature2] == 0) | \n                                                               df[feature1].isna() | df[feature2].isna())\n            \n            # Create B/A feature, handle similarly\n            new_feature_name2 = f\"{feature2}div{feature1}\"\n            df[new_feature_name2] = df[feature2] / df[feature1]\n            df[new_feature_name2] = df[new_feature_name2].mask((df[feature1] == 0) | (df[feature2] == 0) | \n                                                               df[feature1].isna() | df[feature2].isna())\n\n    return df\n\nfeature_pairs = [\n    ('PreInt_EduHx-computerinternet_hoursday', 'Basic_Demos-Age'),\n    ('Basic_Demos-Age', 'SDS-SDS_Total_T'),\n    ('FGC-FGC_SRR_Zone', 'SDS-SDS_Total_T'),\n    ('BIA-BIA_BMC', 'Physical-HeartRate'),\n    #('Fitness_Endurance-Season', 'Physical-Waist_Circumference'),\n    ('BIA-BIA_Fat', 'Physical-BMI'),\n    ('PreInt_EduHx-Season', 'Fitness_Endurance-Season'),\n    ('SDS-SDS_Total_T', 'Physical-Systolic_BP'),\n    ('BIA-BIA_Activity_Level_num', 'FGC-FGC_PU_Zone')\n]\n\ntrain = create_interaction_features(train,feature_pairs)\ntest = create_interaction_features(test,feature_pairs)\ntrain = create_division_features(train,feature_pairs)\ntest = create_division_features(test,feature_pairs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:21:58.820332Z","iopub.execute_input":"2024-12-02T04:21:58.821269Z","iopub.status.idle":"2024-12-02T04:21:58.885540Z","shell.execute_reply.started":"2024-12-02T04:21:58.821230Z","shell.execute_reply":"2024-12-02T04:21:58.884475Z"}},"outputs":[{"name":"stdout","text":"feature1: PreInt_EduHx-computerinternet_hoursday, feature2: Basic_Demos-Age\nfeature1: Basic_Demos-Age, feature2: SDS-SDS_Total_T\nfeature1: FGC-FGC_SRR_Zone, feature2: SDS-SDS_Total_T\nfeature1: BIA-BIA_BMC, feature2: Physical-HeartRate\nfeature1: BIA-BIA_Fat, feature2: Physical-BMI\nfeature1: SDS-SDS_Total_T, feature2: Physical-Systolic_BP\nfeature1: BIA-BIA_Activity_Level_num, feature2: FGC-FGC_PU_Zone\nfeature1: PreInt_EduHx-computerinternet_hoursday, feature2: Basic_Demos-Age\nfeature1: Basic_Demos-Age, feature2: SDS-SDS_Total_T\nfeature1: FGC-FGC_SRR_Zone, feature2: SDS-SDS_Total_T\nfeature1: BIA-BIA_BMC, feature2: Physical-HeartRate\nfeature1: BIA-BIA_Fat, feature2: Physical-BMI\nfeature1: SDS-SDS_Total_T, feature2: Physical-Systolic_BP\nfeature1: BIA-BIA_Activity_Level_num, feature2: FGC-FGC_PU_Zone\nfeature1: PreInt_EduHx-computerinternet_hoursday, feature2: Basic_Demos-Age\nfeature1: Basic_Demos-Age, feature2: SDS-SDS_Total_T\nfeature1: FGC-FGC_SRR_Zone, feature2: SDS-SDS_Total_T\nfeature1: BIA-BIA_BMC, feature2: Physical-HeartRate\nfeature1: BIA-BIA_Fat, feature2: Physical-BMI\nfeature1: SDS-SDS_Total_T, feature2: Physical-Systolic_BP\nfeature1: BIA-BIA_Activity_Level_num, feature2: FGC-FGC_PU_Zone\nfeature1: PreInt_EduHx-computerinternet_hoursday, feature2: Basic_Demos-Age\nfeature1: Basic_Demos-Age, feature2: SDS-SDS_Total_T\nfeature1: FGC-FGC_SRR_Zone, feature2: SDS-SDS_Total_T\nfeature1: BIA-BIA_BMC, feature2: Physical-HeartRate\nfeature1: BIA-BIA_Fat, feature2: Physical-BMI\nfeature1: SDS-SDS_Total_T, feature2: Physical-Systolic_BP\nfeature1: BIA-BIA_Activity_Level_num, feature2: FGC-FGC_PU_Zone\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"missing_percent_train = train.isnull().mean() * 100\nmissing_percent_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:22:05.029579Z","iopub.execute_input":"2024-12-02T04:22:05.030398Z","iopub.status.idle":"2024-12-02T04:22:05.042990Z","shell.execute_reply.started":"2024-12-02T04:22:05.030359Z","shell.execute_reply":"2024-12-02T04:22:05.041972Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"Basic_Demos-Enroll_Season                        0.000000\nBasic_Demos-Age                                  0.000000\nBasic_Demos-Sex                                  0.000000\nCGAS-Season                                      0.000000\nCGAS-CGAS_Score                                  0.000000\n                                                  ...    \nPhysical-BMIdivBIA-BIA_Fat                       0.255848\nSDS-SDS_Total_TdivPhysical-Systolic_BP           0.000000\nPhysical-Systolic_BPdivSDS-SDS_Total_T           0.000000\nBIA-BIA_Activity_Level_numdivFGC-FGC_PU_Zone    44.736842\nFGC-FGC_PU_ZonedivBIA-BIA_Activity_Level_num    44.736842\nLength: 78, dtype: float64"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"def quadratic_weighted_kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n\ndef threshold_Rounder(oof_non_rounded, thresholds):\n    return np.where(oof_non_rounded < thresholds[0], 0,\n                    np.where(oof_non_rounded < thresholds[1], 1,\n                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n\ndef evaluate_predictions(thresholds, y_true, oof_non_rounded):\n    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n    return -quadratic_weighted_kappa(y_true, rounded_p)\n\ndef TrainML(model_class, test_data):\n    \n    X = train.drop(['sii'], axis=1)\n    y = train['sii']\n    test_data = test_data.drop(['sii'], axis=1)\n    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n    \n    train_S = []\n    test_S = []\n    \n    oof_non_rounded = np.zeros(len(y), dtype=float) \n    oof_rounded = np.zeros(len(y), dtype=int) \n    test_preds = np.zeros((len(test_data), n_splits))\n\n    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n\n        model = clone(model_class)\n        model.fit(X_train, y_train)\n\n        y_train_pred = model.predict(X_train)\n        y_val_pred = model.predict(X_val)\n\n        oof_non_rounded[test_idx] = y_val_pred\n        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n        oof_rounded[test_idx] = y_val_pred_rounded\n\n        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n\n        train_S.append(train_kappa)\n        test_S.append(val_kappa)\n        \n        test_preds[:, fold] = model.predict(test_data)\n        \n        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n        clear_output(wait=True)\n\n    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n\n    KappaOPtimizer = minimize(evaluate_predictions,\n                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n                              method='Nelder-Mead') # Nelder-Mead | # Powell\n    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n    \n    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n\n    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n\n    tpm = test_preds.mean(axis=1)\n    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n    \n    submission = pd.DataFrame({\n        'id': test_id,\n        'sii': tpTuned\n    })\n\n\n    return submission, tKappa\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Function to preprocess data for LightGBM\ndef preprocess_data(df):\n    # Identify non-numeric columns\n    non_numeric_cols = df.select_dtypes(include=['object']).columns\n    \n    # Apply label encoding to non-numeric columns\n    label_encoders = {}\n    for col in non_numeric_cols:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col].astype(str))\n        label_encoders[col] = le\n    \n    return df, label_encoders\n\n\n# Apply preprocessing to both train and test data\ntrain_preprocessed, train_encoders = preprocess_data(train)\ntest_preprocessed, _ = preprocess_data(test)\n\n\n\n\nbest_params_lgbm = {\n    'learning_rate': 0.046,\n    'max_depth': 12,\n    'num_leaves': 478,\n    'min_data_in_leaf': 13,\n    'feature_fraction': 0.893,\n    'bagging_fraction': 0.784,\n    'bagging_freq': 4,\n    'lambda_l1': 10,\n    'lambda_l2': 0.01\n}\n\nbest_params_xgb = {\n'subsample': 0.8,\n'reg_lambda': 100, \n'reg_alpha': 0, \n'n_estimators': 500,\n'min_child_weight': 5,\n'max_depth': 3, \n'learning_rate': 0.01,\n'gamma': 0, \n'colsample_bytree': 1.0\n}\n\nbest_params_catboost = {\n    'random_strength': 1,\n 'learning_rate': 0.01,\n 'l2_leaf_reg': 9, \n 'iterations': 500, \n 'depth': 4, \n 'border_count': 64,\n 'bagging_temperature': 0.2}\n\nbest_params_rf =  {'n_estimators': 400,\n                   'min_samples_split': 5, \n                   'min_samples_leaf': 4, \n                   'max_features': 'sqrt',\n                   'max_depth': 10, \n                   'bootstrap': True}\n\n\nimport numpy as np\nimport pandas as pd\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting  # Required for HistGradientBoosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.ensemble import VotingRegressor\nfrom scipy.optimize import minimize\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features using LabelEncoder\ncate_c = [\n    'Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season',\n    'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season',\n    'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season',\n    'PreInt_EduHx-Season', 'Basic_Demos-Sex'\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:22:09.505226Z","iopub.execute_input":"2024-12-02T04:22:09.505581Z","iopub.status.idle":"2024-12-02T04:22:09.525315Z","shell.execute_reply.started":"2024-12-02T04:22:09.505549Z","shell.execute_reply":"2024-12-02T04:22:09.524161Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"Light = lgb.LGBMRegressor(**best_params_lgbm, random_state=SEED, verbose=-1)\nSubmission_LGBM, k_lgbm = TrainML(Light, test_preprocessed)\n\nXGBoost = xgb.XGBRegressor(**best_params_xgb, random_state=SEED,enable_categorical=True)\nSubmission_XGB, k_xgb = TrainML(XGBoost, test)\n\ncate_c = ['Basic_Demos-Enroll_Season',\n 'CGAS-Season',\n 'Physical-Season',\n 'Fitness_Endurance-Season',\n 'FGC-Season',\n 'BIA-Season',\n 'PAQ_A-Season',\n 'PAQ_C-Season',\n 'SDS-Season',\n 'PreInt_EduHx-Season',\n 'Basic_Demos-Sex'\n        ]\n\nCatBoost = CatBoostRegressor(**best_params_catboost, random_state=SEED, verbose=0,cat_features=cate_c)\nSubmission_CatBoost , k_cat= TrainML(CatBoost, test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:22:17.017950Z","iopub.execute_input":"2024-12-02T04:22:17.018880Z","iopub.status.idle":"2024-12-02T04:22:20.561410Z","shell.execute_reply.started":"2024-12-02T04:22:17.018824Z","shell.execute_reply":"2024-12-02T04:22:20.560502Z"}},"outputs":[{"name":"stderr","text":"Training Folds: 100%|██████████| 5/5 [00:03<00:00,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Mean Train QWK --> 0.6344\nMean Validation QWK ---> 0.3725\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.456\u001b[0m\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.stats import mode\n\nmerged_predictions = Submission_LGBM.merge(Submission_XGB, on=\"id\", suffixes=(\"_lgbm\", \"_xgb\"))\nmerged_predictions = merged_predictions.merge(\n    Submission_CatBoost.rename(columns={\"sii\": \"sii_catboost\"}), on=\"id\"\n)\n\nmerged_predictions\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:47:13.367627Z","iopub.execute_input":"2024-12-02T04:47:13.368067Z","iopub.status.idle":"2024-12-02T04:47:13.384953Z","shell.execute_reply.started":"2024-12-02T04:47:13.368032Z","shell.execute_reply":"2024-12-02T04:47:13.383961Z"}},"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"          id  sii_lgbm  sii_xgb  sii_catboost\n0   00008ff9         0        0             0\n1   000fd460         0        0             0\n2   00105258         0        0             0\n3   00115b9f         0        0             0\n4   0016bb22         1        2             2\n5   001f3379         0        0             0\n6   0038ba98         0        1             1\n7   0068a485         1        1             1\n8   0069fbed         2        2             2\n9   0083e397         2        2             2\n10  0087dd65         2        2             1\n11  00abe655         1        0             1\n12  00ae59c9         1        1             1\n13  00af6387         2        2             2\n14  00bd4359         2        2             2\n15  00c0cd71         1        0             0\n16  00d56d4b         0        0             0\n17  00d9913d         1        1             1\n18  00e6167c         0        0             0\n19  00ebc35d         2        2             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sii_lgbm</th>\n      <th>sii_xgb</th>\n      <th>sii_catboost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>001f3379</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0038ba98</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0068a485</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0069fbed</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0083e397</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0087dd65</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00abe655</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00ae59c9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>00af6387</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00bd4359</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00c0cd71</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>00d56d4b</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>00d9913d</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>00e6167c</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>00ebc35d</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":93},{"cell_type":"code","source":"import pandas as pd\nfrom collections import Counter\n\n# Custom function to calculate the mode robustly\ndef calculate_mode(values):\n    counter = Counter(values)\n    return counter.most_common(1)[0][0]  # Get the most common value\n\n# Apply the function row-wise to calculate the mode\nmerged_predictions[\"sii\"] = merged_predictions[[\"sii_lgbm\", \"sii_xgb\", \"sii_catboost\"]].apply(\n    lambda row: calculate_mode(row), axis=1\n)\n\nmerged_predictions = merged_predictions.drop([\"sii_lgbm\", \"sii_xgb\", \"sii_catboost\"], axis=1)\nmerged_predictions\n\nmerged_predictions.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T04:47:16.313739Z","iopub.execute_input":"2024-12-02T04:47:16.314431Z","iopub.status.idle":"2024-12-02T04:47:16.330386Z","shell.execute_reply.started":"2024-12-02T04:47:16.314392Z","shell.execute_reply":"2024-12-02T04:47:16.329123Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"merged_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T05:07:41.172444Z","iopub.execute_input":"2024-12-02T05:07:41.173293Z","iopub.status.idle":"2024-12-02T05:07:41.187432Z","shell.execute_reply.started":"2024-12-02T05:07:41.173251Z","shell.execute_reply":"2024-12-02T05:07:41.186404Z"}},"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"          id  sii\n0   00008ff9    0\n1   000fd460    0\n2   00105258    0\n3   00115b9f    0\n4   0016bb22    2\n5   001f3379    0\n6   0038ba98    1\n7   0068a485    1\n8   0069fbed    2\n9   0083e397    2\n10  0087dd65    2\n11  00abe655    1\n12  00ae59c9    1\n13  00af6387    2\n14  00bd4359    2\n15  00c0cd71    0\n16  00d56d4b    0\n17  00d9913d    1\n18  00e6167c    0\n19  00ebc35d    2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sii</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>001f3379</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0038ba98</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0068a485</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0069fbed</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0083e397</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0087dd65</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00abe655</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00ae59c9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>00af6387</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00bd4359</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00c0cd71</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>00d56d4b</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>00d9913d</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>00e6167c</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>00ebc35d</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":95}]}